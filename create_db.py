import os
from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import PyMuPDFLoader, CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from tqdm import tqdm
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import config


def load_documents():
    documents = []

    # åŠ è½½ PDF æ–‡ä»¶
    pdf_files = [f for f in os.listdir(config.BOOKS_DIR) if f.endswith(".pdf")]
    if not pdf_files:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ° PDF æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ books æ–‡ä»¶å¤¹ï¼")
    else:
        print(f"ğŸ“‚ åœ¨ books æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ° {len(pdf_files)} ä¸ª PDF æ–‡ä»¶ï¼Œå¼€å§‹åŠ è½½...")

    for pdf_file in pdf_files:
        pdf_path = os.path.join(config.BOOKS_DIR, pdf_file)
        print(f"ğŸ“– æ­£åœ¨åŠ è½½æ–‡ä»¶ï¼š{pdf_path}")
        loader = PyMuPDFLoader(pdf_path)
        documents.extend(loader.load())

    # åŠ è½½ CSV æ–‡ä»¶
    csv_files = [f for f in os.listdir(config.BOOKS_DIR) if f.endswith(".csv")]
    if not csv_files:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ° CSV æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ books æ–‡ä»¶å¤¹ï¼")
    else:
        print(f"ğŸ“‚ åœ¨ books æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶ï¼Œå¼€å§‹åŠ è½½...")

    for csv_file in csv_files:
        csv_path = os.path.join(config.BOOKS_DIR, csv_file)
        print(f"ğŸ“– æ­£åœ¨åŠ è½½æ–‡ä»¶ï¼š{csv_path}")
        loader = CSVLoader(csv_path)
        documents.extend(loader.load())

    return documents


def create_vector_db():
    # 1. åŠ è½½æ–‡æ¡£
    documents = load_documents()
    print(f"âœ… å…±åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µï¼Œå¼€å§‹è¿›è¡Œæ–‡æœ¬åˆ‡åˆ†...")

    # 2. æ–‡æœ¬åˆ‡åˆ†
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.CHUNK_SIZE, chunk_overlap=config.CHUNK_OVERLAP
    )
    docs = text_splitter.split_documents(documents)
    print(f"ğŸ“„ æ–‡æœ¬åˆ‡åˆ†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(docs)} ä¸ªæ–‡æœ¬å—ã€‚")

    # 3. åˆå§‹åŒ– Embeddings
    embedding = OpenAIEmbeddings(
        openai_api_key=config.OPENAI_API_KEY,
        openai_api_base=config.OPENAI_API_BASE,
    )

    # 4. åˆ›å»ºå‘é‡å­˜å‚¨
    print("ğŸ“¡ æ„å»º FAISS å‘é‡å­˜å‚¨...")
    vectorstore = FAISS.from_documents(docs, embedding)

    # 5. ä¿å­˜ç´¢å¼•
    vectorstore.save_local(config.FAISS_INDEX_PATH)
    print("âœ… å‘é‡ç´¢å¼•å·²ä¿å­˜ï¼")


if __name__ == "__main__":
    create_vector_db()
